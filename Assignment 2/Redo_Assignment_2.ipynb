{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Redo Assignment 2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tausifshareff/Data-Science/blob/master/Assignment%202/Redo_Assignment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOAr3l7yiBue",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "1d5d38c1-7015-4d54-a26e-aca2db0df671"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk import ngrams\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "import re\n",
        "from itertools import chain\n",
        "from sklearn import naive_bayes, metrics\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBw1NWwQi7S4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to read and process CSV files\n",
        "def read_file(path, val):\n",
        "  data = np.loadtxt(path, dtype='str', delimiter='\\n')\n",
        "  array = []\n",
        "  for i in data:\n",
        "    i = str(i)\n",
        "    tmp = str(np.char.strip(np.char.strip(i, '['), ']'))\n",
        "    quote_rem = re.sub(\"\\'\", '', tmp)\n",
        "    space_rem = re.sub(' ', '', quote_rem)\n",
        "    final_list = space_rem.split(',')\n",
        "    array.append(final_list)\n",
        "  \n",
        "  return identify_label(array, val)\n",
        "\n",
        "# Optional function to label the pos and neg corpus\n",
        "def identify_label(array, val):\n",
        "  labelled_array = [(x, val) for x in array]\n",
        "  return labelled_array\n",
        "\n",
        "# Unused Bigram Generation Function From a Pandas Column\n",
        "def generate_bigram(corpus,val):\n",
        "  corpus[0] = corpus[0].apply(lambda x: list(ngrams(x,2)))\n",
        "  temp = [(x,val) for x in list(chain(*corpus[0]))]\n",
        "  del corpus\n",
        "  return pd.DataFrame(temp)\n",
        "\n",
        "# Unused Unigram Generation Function From a Pandas Column\n",
        "def generate_unigram(corpus,val):\n",
        "  corpus[0] = corpus[0].apply(lambda x: list(ngrams(x,1)))\n",
        "  temp = [(x,val) for x in list(chain(*corpus[0]))]\n",
        "  del corpus\n",
        "  return pd.DataFrame(temp)\n",
        "\n",
        "# Classification Model to Train and Validate Predictions\n",
        "def build_model(mod, x_train, y_train, x_val, y_val, al):\n",
        "  modl = mod(alpha = al)\n",
        "  modl.fit(x_train, y_train)\n",
        "  y_pred = modl.predict(x_val)\n",
        "    \n",
        "  return metrics.accuracy_score(y_pred, y_val)\n",
        "\n",
        "# Shuffling Rows in a Dataframe\n",
        "def shuffle_frame(dataframe):\n",
        "  temp = (dataframe.index.values).copy()\n",
        "  np.random.shuffle(temp)\n",
        "  dataframe = dataframe.set_index(temp)\n",
        "  del temp\n",
        "  dataframe = dataframe.sort_index()\n",
        "  dataframe = dataframe.reset_index(drop=True)\n",
        "  return dataframe"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAZgXcT1zyYV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reading and merging the CSV files\n",
        "train_pos = pd.DataFrame(np.array(read_file(\"drive/Colab Notebooks/MSCI 641/train pos.csv\", 1)))\n",
        "train_neg = pd.DataFrame(np.array(read_file(\"drive/Colab Notebooks/MSCI 641/train neg.csv\", 0)))\n",
        "test_pos = pd.DataFrame(np.array(read_file(\"drive/Colab Notebooks/MSCI 641/test pos.csv\", 1)))\n",
        "test_neg = pd.DataFrame(np.array(read_file(\"drive/Colab Notebooks/MSCI 641/test neg.csv\", 0)))\n",
        "val_pos = pd.DataFrame(np.array(read_file(\"drive/Colab Notebooks/MSCI 641/val pos.csv\", 1)))\n",
        "val_neg = pd.DataFrame(np.array(read_file(\"drive/Colab Notebooks/MSCI 641/val neg.csv\", 0)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQ7MOBMFkRoC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Merging positive and negative datasets\n",
        "train = pd.concat([train_pos, train_neg], axis=0)\n",
        "test = pd.concat([test_pos, test_neg], axis=0)\n",
        "val = pd.concat([val_pos, val_neg], axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HekBrNcPuIna",
        "colab_type": "text"
      },
      "source": [
        "# For Unigrams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3e0QodSlACB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "c4f5cc5f-0fe4-45b7-871c-d0b0c4e0a6fa"
      },
      "source": [
        "countvec = CountVectorizer(analyzer=\"word\", ngram_range=(1,1))\n",
        "countvec.fit([\" \".join(x) for x in train[0]])\n",
        "X_train = countvec.transform([\" \".join(x) for x in train[0]])\n",
        "Y_train = list(train[1].values)\n",
        "\n",
        "X_val = countvec.transform([\" \".join(x) for x in val[0]])\n",
        "Y_val = list(val[1].values)\n",
        "\n",
        "X_test = countvec.transform([\" \".join(x) for x in test[0]])\n",
        "Y_test = list(test[1].values)\n",
        "\n",
        "print(\"Predicting Unigram Sentiments:\")\n",
        "print(\"\\n\")\n",
        "print(\"Tuning of alpha in range 0 to 9 in steps 0.2\")\n",
        "tune = [build_model(naive_bayes.MultinomialNB, X_train, Y_train, X_val, Y_val, x) for x in np.arange(0,9,0.2)]\n",
        "best_param = round(np.arange(0,9,0.2)[tune.index(max(tune))], 2)\n",
        "print(\"Best alpha parameter value obtained by tuning on validation data: alpha =\", best_param)\n",
        "print(\"Test accuracy with tuned alpha value:\", round(100*build_model(naive_bayes.MultinomialNB, X_train, Y_train, X_test, Y_test, best_param),2))\n",
        "print(\"\\n\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting Unigram Sentiments:\n",
            "\n",
            "\n",
            "Tuning of alpha in range 0 to 9 in steps 0.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best alpha parameter value obtained by tuning on validation data: alpha = 1.2\n",
            "Test accuracy with tuned alpha value: 72.47\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "infVqYjrtWym",
        "colab_type": "text"
      },
      "source": [
        "# For Bigrams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2ORTtaEti7u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "55460d86-0779-4418-e0de-9e79c0cbb499"
      },
      "source": [
        "countvec = CountVectorizer(analyzer=\"word\", ngram_range=(2,2))\n",
        "countvec.fit([\" \".join(x) for x in train[0]])\n",
        "X_train = countvec.transform([\" \".join(x) for x in train[0]])\n",
        "Y_train = list(train[1].values)\n",
        "\n",
        "X_val = countvec.transform([\" \".join(x) for x in val[0]])\n",
        "Y_val = list(val[1].values)\n",
        "\n",
        "X_test = countvec.transform([\" \".join(x) for x in test[0]])\n",
        "Y_test = list(test[1].values)\n",
        "\n",
        "print(\"Predicting Bigram Sentiments:\")\n",
        "print(\"\\n\")\n",
        "print(\"Tuning of alpha in range 0 to 9 in steps 0.2\")\n",
        "tune = [build_model(naive_bayes.MultinomialNB, X_train, Y_train, X_val, Y_val, x) for x in np.arange(0,9,0.2)]\n",
        "best_param = round(np.arange(0,9,0.2)[tune.index(max(tune))], 2)\n",
        "print(\"Best alpha parameter value obtained by tuning on validation data: alpha =\", best_param)\n",
        "print(\"Test accuracy with tuned alpha value:\", round(100*build_model(naive_bayes.MultinomialNB, X_train, Y_train, X_test, Y_test, best_param),2))\n",
        "print(\"\\n\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting Bigram Sentiments:\n",
            "\n",
            "\n",
            "Tuning of alpha in range 0 to 9 in steps 0.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best alpha parameter value obtained by tuning on validation data: alpha = 0.8\n",
            "Test accuracy with tuned alpha value: 75.11\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2nTNjZsy7UC",
        "colab_type": "text"
      },
      "source": [
        "# For Unigrams+Bigrams\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfPlSPilIxMF",
        "colab_type": "code",
        "outputId": "ac46001a-cf4c-4932-addd-a30b9af273a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        }
      },
      "source": [
        "# For Unigrams+Bigrams\n",
        "countvec = CountVectorizer(analyzer=\"word\", ngram_range=(1,2))\n",
        "countvec.fit([\" \".join(x) for x in train[0]])\n",
        "\n",
        "X_train = countvec.transform([\" \".join(x) for x in train[0]])\n",
        "Y_train = list(train[1].values)\n",
        "\n",
        "X_val = countvec.transform([\" \".join(x) for x in val[0]])\n",
        "Y_val = list(val[1].values)\n",
        "\n",
        "X_test = countvec.transform([\" \".join(x) for x in test[0]])\n",
        "Y_test = list(test[1].values)\n",
        "\n",
        "print(\"Predicting Unigram+Bigram Sentiments:\")\n",
        "print(\"\\n\")\n",
        "print(\"Tuning of alpha in range 0 to 9 in steps 0.2\")\n",
        "tune = [build_model(naive_bayes.MultinomialNB, X_train, Y_train, X_val, Y_val, x) for x in np.arange(0,9,0.2)]\n",
        "best_param = round(np.arange(0,9,0.2)[tune.index(max(tune))], 2)\n",
        "print(\"Best alpha parameter value obtained by tuning on validation data: alpha =\", best_param)\n",
        "print(\"Test accuracy with tuned alpha value:\", round(100*build_model(naive_bayes.MultinomialNB, X_train, Y_train, X_test, Y_test, best_param),2))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting Unigram+Bigram Sentiments:\n",
            "\n",
            "\n",
            "Tuning of alpha in range 0 to 9 in steps 0.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best alpha parameter value obtained by tuning on validation data: alpha = 0.4\n",
            "Test accuracy with tuned alpha value: 75.96\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}